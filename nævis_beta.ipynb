{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPWY2XZ7QDGbRF310pQ2zIe"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install -q -U google-generativeai\n",
        "\n",
        "import textwrap\n",
        "import google.generativeai as genai\n",
        "\n",
        "from IPython.display import display, Markdown\n",
        "from google.colab import userdata, files\n",
        "\n",
        "GOOGLE_API_KEY=userdata.get('GOOGLE_API_KEY')\n",
        "genai.configure(api_key=GOOGLE_API_KEY)\n",
        "model = genai.GenerativeModel('gemini-1.5-pro-exp-0801')\n",
        "\n",
        "character_name = userdata.get('character_name')\n",
        "character_info = userdata.get('character_info')\n",
        "kwangya_info = userdata.get('kwangya_info')\n",
        "\n",
        "Fan = input()\n",
        "\n",
        "def to_markdown(text):\n",
        "  text = text.replace('•', ' *')\n",
        "  return Markdown(textwrap.indent(text, '> ', predicate=lambda _: True))\n",
        "\n",
        "initial_prompt = f\"\"\"\n",
        "이제부터 당신은 {character_name}라는 캐릭터로 대화합니다.\n",
        "{character_name}은 {character_info}입니다.\n",
        "광야에 대해서는 {kwangya_info}를 참고하세요.\n",
        "상대방의 이름은 {Fan}이며,대화시 답변은 2~3줄 이내로 간단하게 진행합니다.\n",
        "\"\"\"\n",
        "response = model.generate_content(initial_prompt)\n",
        "context = initial_prompt"
      ],
      "metadata": {
        "id": "lIvrW0AlBC9n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "while True:\n",
        "  USER = input()\n",
        "\n",
        "  if USER == 'F':\n",
        "    prompt = userdata.get('End')\n",
        "    response = model.generate_content(prompt)\n",
        "    context += f\"\\n{Fan}: {USER}\\n{character_name}: {response.text}\"\n",
        "    markdown_text = to_markdown(response.text)\n",
        "    display(markdown_text)\n",
        "    break\n",
        "\n",
        "  else:\n",
        "    prompt = f\"{context}\\n{Fan}: {USER}\\n{character_name}: \"\n",
        "    response = model.generate_content(prompt)\n",
        "    context += f\"\\n{Fan}: {USER}\\n{character_name}: {response.text}\"\n",
        "    markdown_text = to_markdown(response.text)\n",
        "    display(markdown_text)"
      ],
      "metadata": {
        "id": "W6IdQIsCD4es"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
